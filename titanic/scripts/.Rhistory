#cuentaoro2
cuentapais2=aggregate(X~NOC, data = cuentaoro2, FUN = sum)
cuentapais2
View(cuentapais2)
cuentapais=aggregate(X~Medal + Year+NOC, data=medallas, FUN=length)
#cuentapais
cuentaoro = cuentapais[cuentapais$Medal=="Gold",]
#cuentaoro
cuentaoro2=cuentaoro[cuentaoro$Year>=1960 & cuentaoro$Year<=1996, ]
#cuentaoro2
cuentapais2=aggregate(X~NOC, data = cuentaoro2, FUN = sum)
#cuentapais2
paisgana=cuentapais2[cuentapais2$X==max(cuentapais2$X),1]
paisgana
cuentapais=aggregate(X~Medal + Year+NOC, data=medallas, FUN=length)
#cuentapais
cuentaoro = cuentapais[cuentapais$Medal=="Gold",]
#cuentaoro
cuentaoro2=cuentaoro[cuentaoro$Year>=1960 & cuentaoro$Year<=1996, ]
#cuentaoro2
cuentapais2=aggregate(X~NOC, data = cuentaoro2, FUN = sum)
#cuentapais2
paisgana=cuentapais2[cuentapais2$X==max(cuentapais2$X),1]
droplevels(paisgana)
paisgana
cuentapais=aggregate(X~Medal + Year+NOC, data=medallas, FUN=length)
#cuentapais
cuentaoro = cuentapais[cuentapais$Medal=="Gold",]
#cuentaoro
cuentaoro2=cuentaoro[cuentaoro$Year>=1960 & cuentaoro$Year<=1996, ]
#cuentaoro2
cuentapais2=aggregate(X~NOC, data = cuentaoro2, FUN = sum)
#cuentapais2
paisgana=cuentapais2[cuentapais2$X==max(cuentapais2$X),1]
droplevels(paisgana)
cuentapais=aggregate(X~Medal + Year+NOC, data=medallas, FUN=length)
#cuentapais
cuentaoro = cuentapais[cuentapais$Medal=="Gold",]
#cuentaoro
cuentaoro2=cuentaoro[cuentaoro$Year>=1960 & cuentaoro$Year<=1996, ]
#cuentaoro2
cuentapais2=aggregate(X~NOC, data = cuentaoro2, FUN = sum)
#cuentapais2
paisgana=cuentapais2[cuentapais2$X==max(cuentapais2$X),1]
droplevels(paisgana)
sprintf("El país que mas medallas de oro ha ganado entre 1960 y 1996 es: %s.",paisgana)
cuentapais=aggregate(X~Medal + Year+NOC, data=medallas, FUN=length)
#cuentapais
cuentaoro = cuentapais[cuentapais$Medal=="Gold",]
#cuentaoro
cuentaoro2=cuentaoro[cuentaoro$Year>=1960 & cuentaoro$Year<=1996, ]
#cuentaoro2
cuentapais2=aggregate(X~NOC, data = cuentaoro2, FUN = sum)
#cuentapais2
paisgana=cuentapais2[cuentapais2$X==max(cuentapais2$X),1]
#droplevels(paisgana)
sprintf("El país que mas medallas de oro ha ganado entre 1960 y 1996 es: %s.",paisgana)
knitr::opts_chunk$set(echo = TRUE)
df=medallas
max(df$Year)
df$Year
which.max(table(df$NOC))
count(df, Event.gender)
library(dplyr)
library(dbplyr)
library(dtplyr)
count(df, Event.gender)
length(unique(as.factor(df$City)))
df=medallas
#df$Year
max(df$Year)
which.max(table(df$NOC))
knitr::opts_chunk$set(echo = TRUE)
barplot(sample(30:40,size=5,replace = T),beside = T, xlab = edad)
barplot(sample(30:40,size=5,replace = T),beside = T, xlab = "edad")
barplot(sample(30:40,size=5,replace = T),beside = T, xlab = "edad", ylim = 40)
barplot(sample(30:40,size=5,replace = T),beside = T, xlab = "edad", ylim = c(0:40))
barplot(sample(30:40,size=5,replace = T),beside = T, xlab = "edad", ylim = c(0:40))
barplot(sample(30:40,size=5,replace = T),beside = T, xlab = "edad", ylim = c(0,40))
alumnos = c("manolito","juanita","fernandito","estebita","mariela","conchita")
pie(alumnos)
alumnos = c("manolito","juanita","fernandito","estebita","mariela","conchita")
pie(table(alumnos))
dn = read.table(DNase)
help(DNase)
head(DNase)
#help(DNase)
dn = DNase
head(dn)
#help(DNase)
dn = DNase
head(dn)
barplot(dn$density, beside = T)
#help(DNase)
dn = DNase
head(dn)
barplot(dn$density, beside = T, cmap = "blues")
#help(DNase)
dn = DNase
head(dn)
barplot(dn$density, beside = T, map = "blues")
#help(DNase)
dn = DNase
head(dn)
barplot(dn$density, beside = T, col = "blues")
#help(DNase)
dn = DNase
head(dn)
barplot(dn$density, beside = T, colmap = "blues")
#help(DNase)
dn = DNase
head(dn)
barplot(dn$density, beside = T, col = "blue")
#help(DNase)
dn = DNase
head(dn)
barplot(dn$density)
#help(DNase)
dn = DNase
head(dn)
barplot(dn$density, legend.text = T)
#help(DNase)
dn = DNase
head(dn)
barplot(dn$density, legend = T)
#help(DNase)
dn = DNase
head(dn)
barplot(table(dn$density))
train = read.csv("../datasets/train.csv", row.names = 1)
test = read.csv("../datasets/test.csv")
# Eliminar las columnas innecesarias del data frame
df = train[,c(-3,-8,-10)]
# Renombrar variables
names(df) = c("Superviviente", "clase", "genero", "edad", "SibSp", "Parch", "Tarifa", "Puerto")
# Codificar como factor la variable de clasificación
df$Superviviente = factor(df$Superviviente, levels = c(0,1))
# convertir las variables categoricas a factores:
df$genero = factor(df$genero, labels = c("mujer","hombre"))
df$clase = factor(df$clase, levels = c(3,2,1), ordered = TRUE)
df$SibSp = factor(df$SibSp, ordered = TRUE)
df$Parch = factor(df$Parch, levels = c(0,1,2,3,4,5,6,9),ordered = TRUE)
# convertir las variables categoricas a factores en el cojunto de test:
test$Sex = factor(test$Sex, labels = c(1,2))
test$Pclass = factor(test$Pclass, levels = c(3,2,1), ordered = TRUE)
test$SibSp = factor(test$SibSp, ordered = TRUE)
test$Parch = factor(test$Parch, ordered = TRUE)
head(df)
str(df)
summary(df)
cual.col = c()
for (i in names(df)) {
if ("factor" %in% class(df[,i])){
cual.col = c(cual.col,i)
}
}
library(gmodels)
for (i in cual.col) {
if (i != "Superviviente" & i!="div1") {
plot(table(df[,i],df[,"Superviviente"]), xlab = i, ylab = "Superviviente",
main = paste("Superviviente vs",i), col = c("indianred4","lightgreen"))
CrossTable(df[,i],df[,"Superviviente"], prop.chisq = FALSE, dnn = c(i,"Superviviente"),
format = "SPSS")
}
}
ftable(df$genero, df$clase, df$Superviviente)
ftable(100*round(prop.table(table(df$genero, df$clase, df$Superviviente)),3))
boxplot(df$edad, col = "lightblue", notch = FALSE, main = "Edad")
points(mean(df$edad), col = "gold", pch=19, cex = 1.5)
summC = summary(df$edad)
print("Tabla Resumen de Edad")
print(summC)
boxplot(df$edad~df$Superviviente, col = "deepskyblue",
main = "Edades de los Supervivientes",
ylab = "Edades", xlab = "Superviviente")
medias = aggregate(df$edad~df$Superviviente, FUN = mean)
points(medias, col = "floralwhite", pch = 19)
tSum = by(df$edad,df$Superviviente, FUN = summary)
print(tSum)
e = df$edad
# em = df$edad[df$genero == "mujer"]
# eh = df$edad[,df$genero=="hombre"]
n= length(e)
k1 = ceiling(sqrt(n))
print(k1)
k2 = ceiling(1+log(n,2))
print(k2)
As = 3.5*sd(e)*n^(-1/3)
k3 = ceiling(diff(range(e))/As)
print(k3)
Afd = 2*(quantile(e,0.75,names = FALSE, na.rm = TRUE)-quantile(e,0.25,names = FALSE, na.rm = TRUE))*n^(-1/3)
k4 = ceiling(diff(range(e))/Afd)
print(k4)
k5 = nclass.Sturges(e)
print(k5)
#k6 = nclass.scott(e)
#print(k6)
#k7 = nclass.FD(e)
#print(k7)
L = seq(0,80,5)
df$div1 = cut(e, breaks = L, right = FALSE, include.lowest = TRUE)
plot(table(df$div1,df[,"Superviviente"]), xlab = "Edades", ylab = "Superviviente",
main = "Superviviente vs Edades", col = c("indianred4","lightgreen"))
CrossTable(df$div1,df[,"Superviviente"], prop.chisq = FALSE,
dnn = c("Edades","Superviviente"),format = "SPSS")
plot(table(df$div1[df$genero=="mujer"],df$Superviviente[df$genero=="mujer"]), xlab = "Edades", ylab = "Superviviente",
main = "Superviviente vs Edades Mujeres", col = c("indianred4","lightgreen"))
CrossTable(df$div1[df$genero=="mujer"],df[,"Superviviente"][df$genero=="mujer"],
prop.chisq = FALSE,
dnn = c("Edades","Superviviente"),format = "SPSS")
plot(table(df$div1[df$genero=="hombre"],df[,"Superviviente"][df$genero=="hombre"]),
xlab = "Edades", ylab = "Superviviente",
main = "Superviviente vs Edades Hombres", col = c("indianred4","lightgreen"))
CrossTable(df$div1[df$genero=="hombre"],df[,"Superviviente"][df$genero=="hombre"], prop.chisq = FALSE,
dnn = c("Edades","Superviviente"),format = "SPSS")
L = seq(0,80,5)
h = hist(df$edad, breaks = L, right = FALSE,
freq = FALSE,
main = "Histograma de la Edad", xlab = "Edades", ylab = "Frecuencias Absolutas",
#     ylim = c(0,120),
xaxt = "n",
yaxt = "n",
col = "lightgray")
axis(1, at=L)
text(h$mids, h$density/2, labels=h$counts, col="purple")
# lines(density(df$edad), col ="purple", lwd = 2)
rug(jitter(df$edad))
dataset = df
df$edad = ifelse(is.na(df$edad),
ave(df$edad,FUN = function(x) mean(x,na.rm=T)),
df$edad)
# solucionar los NAs del conjunto de test
test$Age = ifelse(is.na(test$Age),
ave(test$Age,FUN = function(x) mean(x,na.rm=T)),
test$Age)
df$genero = as.numeric(factor(df$genero, labels = c(1,2)))
df$Puerto = as.numeric(factor(df$Puerto, labels = c(1,2,3,4)))
df$clase = as.numeric(factor(df$clase, levels = c(3,2,1), labels = c(3,2,1)))
df$SibSp = as.numeric(levels(df$SibSp)[as.integer(df$SibSp)])
df$Parch = as.numeric(levels(df$Parch)[as.integer(df$Parch)])
# Codificar factores del cojunto de test
test$Sex = as.numeric(factor(test$Sex, labels = c(1,2)))
test$Embarked = factor(test$Embarked, labels = c(2,3,4))
levels(test$Embarked) = c(2,3,4,1)
test$Embarked = as.numeric(levels(test$Embarked)[as.integer(test$Embarked)])
test$Pclass = as.numeric(factor(test$Pclass, levels = c(3,2,1), labels = c(3,2,1)))
test$SibSp = as.numeric(levels(test$SibSp)[as.integer(test$SibSp)])
test$Parch = as.numeric(levels(test$Parch)[as.integer(test$Parch)])
# A df la voy a quitar la tarifa y las edades agrupadas
df2 = df[,c(-7,-9)]
# Al test le voy a quitar: PassengerId, Name, Ticket, Fare, Cabin
test2 = test[,c(-1,-3,-8,-9,-10)]
#df2$edad = scale(df2$edad)
# Escalo también el conjunto de test para enviar los datos
#test2$Age = scale(test2$Age)
library(caret)
library(randomForest)
folds = createFolds(df2$Superviviente, k = 10)
cv_rf = lapply(folds, function(x) {
training_fold = df2[-x, ]
test_fold = df2[x, ]
#      classifier = train(form = Superviviente ~ .,
#                         data = df2, method = 'rf')
classifier = randomForest(x = df2[,-1],
y = df2$Superviviente,
mtry = 11)
y_pred = predict(classifier, newdata = test_fold[,-1])
cm = table(test_fold[, 1], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
acc_rf = mean(as.numeric(cv_rf))
acc_sd_rf = sd(as.numeric(cv_rf))
# 0.9360285
# 0.0275173
#classifier = train(form = Superviviente ~ .,
#                         data = df2, method = 'rf')
# classifier
# classifier$bestTune
# 0.7995339
library(xgboost)
library(plyr)
folds = createFolds(df2$Superviviente, k = 10)
cv_xg = lapply(folds, function(x) {
training_fold = df2[-x, ]
test_fold = df2[x, ]
classifier = xgboost(data = as.matrix(df2[,-1]), label = df2$Superviviente,
nrounds = 50, max_depth = 2, eta = 0.3,
gamma = 0, colsample_bytree = 0.8, min_child_weight = 1,
subsample = 0.75)
y_pred = predict(classifier, newdata = as.matrix(test_fold[,-1]))
cm = table(test_fold[, 1], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
acc_xg = mean(as.numeric(cv_xg))
acc_sd_xg = sd(as.numeric(cv_xg))
# 0.475
# 0.2080554
classi_xg = train(form = Superviviente ~.,
data = df2, method = 'xgbTree')
# 0.8155631
#classifier = xgboost(data = as.matrix(training_set[, -11]),
#                     label = training_set$Exited,
#                     nrounds = 10)
#classi_xg
#classi_xg$bestTune
library(xgboost)
classi_rf = train(form = Superviviente ~ .,
data = df2, method = 'rf',
importance = TRUE)
names(test2) = c("clase", "genero", "edad", "SibSp", "Parch", "Puerto")
# test2$Puerto = factor(test2$Puerto, levels = c(4,3,2,1), labels = c(4,3,2,1))
y_pred_rf = predict(classi_rf, newdata = test2)
library(xgboost)
library(plyr)
#classi_rf = train(form = Superviviente ~ .,
#                  data = df2, method = 'xgbtree')
names(test2) = c("clase", "genero", "edad", "SibSp", "Parch", "Puerto")
# test2$Puerto = factor(test2$Puerto, levels = c(4,3,2,1), labels = c(4,3,2,1))
y_pred_xg = predict(classi_xg, newdata = test2)
# Pasar de factor a vector:
out_vect_rf = as.numeric(levels(y_pred_rf)[as.integer(y_pred_rf)])
# Crear el dataframe
out_rf = cbind("PassengerId"= test$PassengerId,
data.frame("Survived"= out_vect_rf))
# write.csv(out_rf, "../datasets/subm_am_rf_300721.csv", row.names = FALSE)
# Pasar de factor a vector:
out_vect_xg = as.numeric(levels(y_pred_xg)[as.integer(y_pred_xg)])
# Crear el dataframe
out_xg = cbind("PassengerId"= test$PassengerId,
data.frame("Survived"= out_vect_xg))
# write.csv(out_xg, "../datasets/subm_am_xg_300721.csv", row.names = FALSE)
setwd("~/Documents/formacion - kaggle/titanic/scripts")
library(e1071)
folds = createFolds(df2$Superviviente, k = 10)
cv_ksvm = lapply(folds, function(x) {
training_fold = df2[-x, ]
test_fold = df2[x, ]
classifier = train(form = Superviviente ~ .,
data = df2,
type = "C-classification",
kernel = "radial")
y_pred = predict(classifier, newdata = test_fold[,-1])
cm = table(test_fold[, 1], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
acc_ksvm = mean(as.numeric(cv))
acc_ksvm = mean(as.numeric(cv_ksvm))
acc_sd_ksvm = sd(as.numeric(cv_ksvm))
acc_ksvm
acc_sd_ksvm
library(e1071)
folds = createFolds(df2$Superviviente, k = 10)
cv_ksvm = lapply(folds, function(x) {
training_fold = df2[-x, ]
test_fold = df2[x, ]
classifier = svm(formula = Superviviente ~ .,
data = df2,
type = "C-classification",
kernel = "radial")
y_pred = predict(classifier, newdata = test_fold[,-1])
cm = table(test_fold[, 1], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
acc_ksvm = mean(as.numeric(cv_ksvm))
acc_sd_ksvm = sd(as.numeric(cv_ksvm))
# 0.8686988
# 0.02422858
classi_ksvm = svm(formula = Purchased ~ .,
data = training_set,
type = "C-classification",
kernel = "radial")
classi_ksvm = train(form = Superviviente ~.,
data = df2,
type = "C-classification",
kernel = "radial")
classi_ksvm$bestTune
classi_ksvm
getModelInfo(model = "C-classifiaction")
folds = createFolds(df2$Superviviente, k = 10)
cv_ksvm = lapply(folds, function(x) {
training_fold = df2[-x, ]
test_fold = df2[x, ]
classifier = svm(formula = Superviviente ~ .,
data = df2,
type = "C-classification",
kernel = "radial",
mtry = 2)
y_pred = predict(classifier, newdata = test_fold[,-1])
cm = table(test_fold[, 1], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
acc_ksvm = mean(as.numeric(cv_ksvm))
acc_sd_ksvm = sd(as.numeric(cv_ksvm))
acc_ksvm
cv_ksvm = lapply(folds, function(x) {
training_fold = df2[-x, ]
test_fold = df2[x, ]
classifier = svm(formula = Superviviente ~ .,
data = df2,
type = "C-classification",
kernel = "radial",
#                    mtry = 2
)
y_pred = predict(classifier, newdata = test_fold[,-1])
cm = table(test_fold[, 1], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
folds = createFolds(df2$Superviviente, k = 10)
cv_ksvm = lapply(folds, function(x) {
training_fold = df2[-x, ]
test_fold = df2[x, ]
classifier = svm(formula = Superviviente ~ .,
data = df2,
type = "C-classification",
kernel = "radial")
#                    mtry = 2)
y_pred = predict(classifier, newdata = test_fold[,-1])
cm = table(test_fold[, 1], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
acc_ksvm = mean(as.numeric(cv_ksvm))
acc_sd_ksvm = sd(as.numeric(cv_ksvm))
acc_ksvm
acc_sd_ksvm
library(e1071)
folds = createFolds(df2$Superviviente, k = 10)
cv_ksvm = lapply(folds, function(x) {
training_fold = df2[-x, ]
test_fold = df2[x, ]
classifier = svm(formula = Superviviente ~ .,
data = df2,
type = "C-classification",
kernel = "radial")
y_pred = predict(classifier, newdata = test_fold[,-1])
cm = table(test_fold[, 1], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
acc_ksvm = mean(as.numeric(cv_ksvm))
acc_sd_ksvm = sd(as.numeric(cv_ksvm))
# 0.8686988
# 0.02422858
# 0.8451773
# 0.02580797
#classi_ksvm = train(form = Superviviente ~.,
#                  data = df2,
#                  type = "C-classification",
#                  kernel = "radial")
classi_ksvm = svm(formula = Purchased ~ .,
data = df2,
type = "C-classification",
kernel = "radial")
classi_ksvm = svm(formula = Superviviente ~ .,
data = df2,
type = "C-classification",
kernel = "radial")
classi_ksvm
View(df2)
df2[,-1] = scale(df2[,-1])
# Escalo también el conjunto de test para enviar los datos
test2 = scale(test2)
View(df2)
library(e1071)
folds = createFolds(df2$Superviviente, k = 10)
cv_ksvm = lapply(folds, function(x) {
training_fold = df2[-x, ]
test_fold = df2[x, ]
classifier = svm(formula = Superviviente ~ .,
data = df2,
type = "C-classification",
kernel = "radial")
y_pred = predict(classifier, newdata = test_fold[,-1])
cm = table(test_fold[, 1], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
acc_ksvm = mean(as.numeric(cv_ksvm))
acc_sd_ksvm = sd(as.numeric(cv_ksvm))
# 0.8686988
# 0.02422858
# 0.8451773
# 0.02580797
#classi_ksvm = train(form = Superviviente ~.,
#                  data = df2,
#                  type = "C-classification",
#                  kernel = "radial")
classi_ksvm = svm(formula = Superviviente ~ .,
data = df2,
type = "C-classification",
kernel = "radial")
classi_ksvm
# classi_ksvm$bestTune
#names(test2) = c("clase", "genero", "edad", "SibSp", "Parch", "Puerto")
# test2$Puerto = factor(test2$Puerto, levels = c(4,3,2,1), labels = c(4,3,2,1))
y_pred_ksvm = predict(classi_ksvm, newdata = test2)
# Pasar de factor a vector:
out_vect_ksvm = as.numeric(levels(y_pred_ksvm)[as.integer(y_pred_ksvm)])
# Crear el dataframe
out_ksvm = cbind("PassengerId"= test$PassengerId,
data.frame("Survived"= out_vect_ksvm))
write.csv(out_xg, "../datasets/subm_am_ksvm_310721.csv", row.names = FALSE)
library(h2o)
View(test2)
h2o.init(nthreads = -1)
h2o.init(nthreads = -1)
